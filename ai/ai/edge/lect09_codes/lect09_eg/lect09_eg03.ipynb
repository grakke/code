{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow识别手写数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-8fe7406c0f13>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x173482f3588>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看数据集图片\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = mnist.train.images[2].reshape(28, 28)\n",
    "plt.imshow(n, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Softmax 回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.matmul(x, W) + b\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9182\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow实现简单的CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据集，并创建默认的InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1662: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建权重和偏置的初始化函数以便重复使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    # 制造随机噪声用以打破完全对称，如 截断的正态分布噪声，标准差为0.1 \n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # 为偏置增加一些小的正值0.1，避免dead neurons\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义卷积层和池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    # tf.nn.conv2d\n",
    "    # x: 输入\n",
    "    # W: 卷积参数，如 [5, 5, 1, 32]表示卷积核的大小为5x5，通道个数为1，卷积核个数为32\n",
    "    # strides: 移动的步长\n",
    "    # padding: 边界处理方式\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # tf.nn.max_pool\n",
    "    # x: 输入的tensor [batch, height, width, channels]\n",
    "    # ksize: 核的大小，[1, 2, 2, 1]表示在1个样本上，2x2大小的核，1个通道\n",
    "    # strides：与ksize类似\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义placeholder，x为特征，y_为真实的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1]) # reshape为28x28的图像，1个通道，-1表示样本数量不固定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义第一个卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "定义第二个卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过两次步长为2x2的池化，大小为原始图像的1/4，即7x7<br/>\n",
    "定义最后的全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为避免过拟合，使用一个Dropout层，训练时随机丢弃一部分节点的数据来减轻过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将Dropout层连接最终的Softmax层，得到最终的概率输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数和优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-5fd016eaa08e>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义准确率的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.86\n",
      "step 200, training accuracy 0.88\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.92\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 0.88\n",
      "step 700, training accuracy 0.88\n",
      "step 800, training accuracy 0.94\n",
      "step 900, training accuracy 0.94\n"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "# for i in range(20000):\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完后，在测试集上进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9596\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "            x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
